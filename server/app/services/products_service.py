"""
ìƒí’ˆ ì¶”ì²œ ì„œë¹„ìŠ¤ ë¡œì§
"""
import asyncio
from typing import TypedDict, Annotated, Sequence, List, Optional
import operator
import json
import re

# --- LangGraph & Agent ê´€ë ¨ ì„í¬íŠ¸ ---
from langgraph.graph import StateGraph, END
from langgraph.prebuilt import ToolNode

# --- LangChain Tools & Retrievers ---
from langchain_core.tools import tool
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage

# --- LLM, DB, Models ---
from app.core.llm_factory import get_llm
from app.core.config import settings
from app.services.search_tools import SEARCH_TOOLS
from app.services.user_vectorization_service import user_vectorization_service
from app.models.recommendation import RecommendationResponse, RecommendedProduct
from app.models.chatbot_models import ChatProduct

# 1. LLM ëª¨ë¸ ì´ˆê¸°í™” (Factory ì‚¬ìš©)
llm = get_llm(temperature=0.1)

# 2. Vector Search Tools ì •ì˜ (Shared Tools ì‚¬ìš©)
tools = SEARCH_TOOLS

# LLMì— tool ë°”ì¸ë”©
llm_with_tools = llm.bind_tools(tools)

# 3. Agent State ì •ì˜
class AgentState(TypedDict):
    messages: Annotated[Sequence[BaseMessage], operator.add]
    persona: str

# 4. Agent í”„ë¡¬í”„íŠ¸ (product_id í¬í•¨í•˜ë„ë¡ ê°œì„ )
SYSTEM_PROMPT = """
ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ í˜ë¥´ì†Œë‚˜ì— ë§ì¶° ê¸ˆìœµ ìƒí’ˆì„ ì¶”ì²œí•˜ëŠ” ì „ë¬¸ AI ì–´ë“œë°”ì´ì € 'ë…¸í›„í•˜ìš°'ì…ë‹ˆë‹¤.

ë‹¹ì‹ ì˜ ì„ë¬´ëŠ” 3ê°€ì§€ì…ë‹ˆë‹¤:
1. [ì‚¬ìš©ì í˜ë¥´ì†Œë‚˜]ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.
2. í˜ë¥´ì†Œë‚˜ì— ê°€ì¥ ì í•©í•œ **ì˜ˆê¸ˆ ë˜ëŠ” ì ê¸ˆ 1ê°œ**, **ì—°ê¸ˆ 1ê°œ**, **í€ë“œ 1ê°œ**ë¥¼ ì¶”ì²œí•˜ê¸° ìœ„í•´, ë‹¹ì‹ ì—ê²Œ ì œê³µëœ [ë„êµ¬(Tools)]ë¥¼ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.
3. ê²€ìƒ‰ëœ ìƒí’ˆ ì •ë³´(Tool observation)ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ê° ìƒí’ˆì„ ì¶”ì²œí•˜ëŠ” êµ¬ì²´ì ì¸ ì´ìœ ë¥¼ ìš”ì•½í•©ë‹ˆë‹¤.

[ì¤‘ìš” ê·œì¹™]
- ë°˜ë“œì‹œ 3ê°€ì§€ ì¹´í…Œê³ ë¦¬(ì˜ˆ/ì ê¸ˆ, ì—°ê¸ˆ, í€ë“œ) ê°ê°ì— ëŒ€í•´ ë„êµ¬ë¥¼ ê²€ìƒ‰í•˜ê³  ì¶”ì²œí•´ì•¼ í•©ë‹ˆë‹¤.
- ì‚¬ìš©ìê°€ 'ì•ˆì •ì¶”êµ¬í˜•'ì´ë©´ 'search_deposits'ë‚˜ 'search_savings'ë¥¼, 'ê³µê²©íˆ¬ìí˜•'ì´ë©´ 'search_funds'ë¥¼ ìš°ì„ ì ìœ¼ë¡œ ê³ ë ¤í•˜ì„¸ìš”.
- í˜ë¥´ì†Œë‚˜ì— ì í•©í•œ ìƒí’ˆì„ ì°¾ì§€ ëª»í•˜ë©´, í•´ë‹¹ í•„ë“œëŠ” nullë¡œ ë¹„ì›Œë‘ê³  ì´ìœ ëŠ” "ì¶”ì²œí•  ìƒí’ˆì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."ë¼ê³  ëª…ì‹œí•˜ì„¸ìš”.
- Tool ê²°ê³¼ì—ì„œ [ID:xxx] í˜•íƒœë¡œ ì œê³µëœ product_idë¥¼ ë°˜ë“œì‹œ JSON ì‘ë‹µì— í¬í•¨í•˜ì„¸ìš”.

ìµœì¢… ì‘ë‹µì€ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”:
{{
  "deposit_or_saving": {{
    "product_id": "...",
    "product_type": "ì˜ˆê¸ˆ" or "ì ê¸ˆ",
    "product_name": "...",
    "company_name": "...",
    "benefit": "ìµœê³  ì—° X.X%",
    "reason": "..."
  }},
  "annuity": {{
    "product_id": "...",
    "product_type": "ì—°ê¸ˆì €ì¶•",
    "product_name": "...",
    "company_name": "...",
    "benefit": "ì„¸ì•¡ê³µì œ 16.5%",
    "reason": "..."
  }},
  "fund": {{
    "product_id": "...",
    "product_type": "í€ë“œ",
    "product_name": "...",
    "company_name": "...",
    "benefit": "ìˆ˜ìµë¥  12.3%",
    "reason": "..."
  }}
}}
"""

# 5. Agent ë…¸ë“œ í•¨ìˆ˜ë“¤
def agent_node(state: AgentState):
    """Agentê°€ ë‹¤ìŒ ì•¡ì…˜ì„ ê²°ì •í•˜ëŠ” ë…¸ë“œ"""
    messages = state["messages"]
    
    # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ + ì´ì „ ëŒ€í™” ë©”ì‹œì§€
    full_messages = [
        {"role": "system", "content": SYSTEM_PROMPT}
    ] + messages
    
    response = llm_with_tools.invoke(full_messages)
    return {"messages": [response]}

def should_continue(state: AgentState):
    """Tool í˜¸ì¶œì´ í•„ìš”í•œì§€ íŒë‹¨"""
    messages = state["messages"]
    last_message = messages[-1]
    
    # Tool í˜¸ì¶œì´ ìˆìœ¼ë©´ "continue", ì—†ìœ¼ë©´ "end"
    if hasattr(last_message, "tool_calls") and last_message.tool_calls:
        return "continue"
    return "end"

# 6. LangGraph êµ¬ì„±
workflow = StateGraph(AgentState)

# ë…¸ë“œ ì¶”ê°€
workflow.add_node("agent", agent_node)
workflow.add_node("tools", ToolNode(tools))

# ì‹œì‘ì  ì„¤ì •
workflow.set_entry_point("agent")

# ì¡°ê±´ë¶€ ì—£ì§€ ì¶”ê°€
workflow.add_conditional_edges(
    "agent",
    should_continue,
    {
        "continue": "tools",
        "end": END
    }
)

# Tool ì‹¤í–‰ í›„ ë‹¤ì‹œ agentë¡œ
workflow.add_edge("tools", "agent")

# Graph ì»´íŒŒì¼
agent_graph = workflow.compile()

# 7. RAG ì„œë¹„ìŠ¤ í´ë˜ìŠ¤
class RAGService:
    async def get_recommendations(self, user_id: int) -> RecommendationResponse:
        """ì‚¬ìš©ì ì„ë² ë”© ê¸°ë°˜ ê¸ˆìœµìƒí’ˆ ì¶”ì²œ"""
        
        # 1. ì‚¬ìš©ì í˜ë¥´ì†Œë‚˜ ê°€ì ¸ì˜¤ê¸°
        user_vector = user_vectorization_service.user_vectors_collection.find_one(
            {"_id": f"user_{user_id}"}
        )
        
        if not user_vector:
            # ì‚¬ìš©ì ë²¡í„°ê°€ ì—†ìœ¼ë©´ ë¨¼ì € ë²¡í„°í™” ì‹¤í–‰
            await user_vectorization_service.vectorize_user(user_id)
            user_vector = user_vectorization_service.user_vectors_collection.find_one(
                {"_id": f"user_{user_id}"}
            )
        
        persona = user_vector["persona_text"]
        
        try:
            # 2. Agent Graph ì‹¤í–‰
            result = await agent_graph.ainvoke({
                "messages": [HumanMessage(content=persona)],
                "persona": persona
            })
            
            
            # 3. ë§ˆì§€ë§‰ ë©”ì‹œì§€ì—ì„œ JSON ì¶”ì¶œ
            last_message = result["messages"][-1]
            response_text = last_message.content
            
            
            # 4. JSON íŒŒì‹±
            # JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ
            json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
            if json_match:
                json_str = json_match.group()
                data = json.loads(json_str)
                
                
                # RecommendedProduct ê°ì²´ë¡œ ë³€í™˜
                deposit_or_saving = None
                if data.get("deposit_or_saving"):
                    deposit_or_saving = RecommendedProduct(**data["deposit_or_saving"])
                
                annuity = None
                if data.get("annuity"):
                    annuity = RecommendedProduct(**data["annuity"])
                
                fund = None
                if data.get("fund"):
                    fund = RecommendedProduct(**data["fund"])
                
                return RecommendationResponse(
                    deposit_or_saving=deposit_or_saving,
                    annuity=annuity,
                    fund=fund
                )
            else:
                print(f"JSON í˜•ì‹ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {response_text}")
                return RecommendationResponse(
                    deposit_or_saving=None,
                    annuity=None,
                    fund=None
                )
        
        except Exception as e:
            print(f"Agent ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            
            return RecommendationResponse(
                deposit_or_saving=None,
                annuity=None,
                fund=None
            )

    def _convert_to_chat_product(self, product: RecommendedProduct, icon: str) -> ChatProduct:
        """RecommendedProductë¥¼ ChatProductë¡œ ë³€í™˜"""
        return ChatProduct(
            id=product.product_id,
            icon=icon,
            type=product.product_type,
            name=product.product_name,
            bank=product.company_name,
            features=[product.reason], # ì´ìœ ë¥¼ íŠ¹ì§•ìœ¼ë¡œ ì‚¬ìš©í•˜ê±°ë‚˜ ë³„ë„ í•„ë“œ í•„ìš”
            stat=product.benefit
        )

    async def get_chat_products(self, user_id: int) -> List[ChatProduct]:
        """ì±—ë´‡ìš© ìƒí’ˆ ì¶”ì²œ ëª©ë¡ ë°˜í™˜"""
        rec_response = await self.get_recommendations(user_id)
        products = []
        
        if rec_response.deposit_or_saving:
            products.append(self._convert_to_chat_product(rec_response.deposit_or_saving, "ğŸ’°"))
            
        if rec_response.annuity:
            products.append(self._convert_to_chat_product(rec_response.annuity, "ğŸ¯"))
            
        if rec_response.fund:
            products.append(self._convert_to_chat_product(rec_response.fund, "ğŸ“ˆ"))
            
        return products

rag_service = RAGService()